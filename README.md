# ai_in_teaching_pc
Repository for AI in teaching

#Things done
You can find the first fine tuned model weights in adapter_model.safetensors file

#TODO:
Parameter-efficient fine-tuning with QLoRA

1. Setting up the NoteBook
2. Install required libraries
3. Loading dataset
4. Create Bitsandbytes configuration
5. Loading the Pre-Trained model
6. Tokenization
7. Test the Model with Zero Shot Inferencing
8. Pre-processing dataset
9. Preparing the model for QLoRA
10. Setup PEFT for Fine-Tuning
11. Train PEFT Adapter

#After the talk TODO:
12. Evaluate the Model Qualitatively (Human Evaluation)
13. Evaluate the Model Quantitatively (with ROUGE Metric)

